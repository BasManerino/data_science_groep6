{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onderzoek Data Science: Films\n",
    "----\n",
    "\n",
    "Voor de casusopdracht van het vak Data Science moet er een pipeline worden gemaakt, waarbij een toegewezen dataset wordt geanalyseerd. Dit data onderzoek is gebaseerd op de dataset over films en is opgezet door groep 6 van klas V2C. De dataset is toegewezen door de Hogeschool Utrecht en bevat onder andere:\n",
    "- filmgegevens, waaronder: duur, genres, taal, land van herkomst, budget en opbrengst;\n",
    "- likes op facebook voor regisseur, hoofdrolspelers, totale cast en de film zelf;\n",
    "- score op IMDB en aantal reviews. \n",
    "\n",
    "\n",
    "#### Hoofdvraag\n",
    "Voor dit onderzoek is er een verplichte onderzoeksvraag, die luidt als volgt: \n",
    "- In hoeverre is de omzet van een film te voorspellen op basis van de populariteit op Facebook en IMDB zelf?\n",
    "\n",
    "#### Onderzoeksvragen\n",
    "Dit onderzoek bevat een aantal onderzoeksvragen die wij zullen behandelen:\n",
    "\n",
    "|Beoordeling                    |Onderzoeksvraag                                                                       |\n",
    "|:------------------------------|:-------------------                                                                  |\n",
    "|Externe dataset                |Hoeveel effect heeft de lengte van een trailer op de omzet van de film?               |\n",
    "|Correlatieonderzoek            |Is een film succesvoller op basis van het aantal likes die een acteur (of acteurs) heeft/hebben op Facebook?                                                                                              | \n",
    "|Supervised machine learning    |In hoeverre is de omzet van een film te voorspellen op basis van de populariteit op Facebook en IMDB zelf?                                                                                                          |\n",
    "|Unsupervised machine learning  |Wat voor voorspelling kan er worden gemaakt over de omzet gebaseerd op de combinatie van het budget en het aantal likes op Facebook e.d.?                                                                                              |\n",
    "|Interactieve visualisatie      |Wat is de netto omzet van de films in een specifiek jaar van uitkomst?                |\n",
    "\n",
    "#### Z-toets\n",
    "Voor de hypothesetoets Z-toets moet het volgende gebeuren.\t\n",
    "Een filmcriticus stelt dat de score van Engelstalige films lager is dan gemiddeld.\n",
    "Wij moeten onderzoeken met de dataset of deze filmcriticus gelijk heeft. We nemen een steekproef (met pandas.DataFrame.sample(n=100,random_state=1)) van 100 Engelstalige films en beschouwen de hele dataset als populatie. Ook nemen we als betrouwbaarheid 90%. We gebruiken van de dataset alleen de filmgegevens waarbij zowel de taal (language) als de score (imdb_score) bekend zijn.\n",
    "\n",
    "#### Teamleden\n",
    "Het team bestaat uit de volgende drie personen:\n",
    "- Sebastiaan Jansen\n",
    "- Skott de Koster\n",
    "- Mustafa Toprak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inhoudsopgave\n",
    "---\n",
    "1. Data collection\n",
    "2. Data processing\n",
    "3. Data cleaning\n",
    "4. Data exploration & analysis\n",
    "5. Model building\n",
    "6. Visualization\n",
    "7. Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 1: Data collection\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De dataset is aan ons gegeven door de Hogeschool Utrecht als onderdeel van de opdracht. Deze dataset houdt een groot CSV bestand in met informatie over films. We hebben dus nu de data verzameld en gaan het nu inlezen.\n",
    "De dataset is opgehaald van de volgende GitHub link: https://github.com/tijmenjoppe/ComputationalModelling-student/tree/master/casus/movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook maken wij gebruik van een externe dataset. Deze externe dataset bevat een link ID naar de trailers van de films die op YouTube te vinden zijn. De externe dataset is opgehaald van de link: https://grouplens.org/datasets/movielens/20m-youtube/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 2: Data processing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan nu de dataset inlezen en verwerken om het beter te kunnen bekijken. Om te beginnen importeren we de benodigde Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deze libraries zijn voor het verwerken van de data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as scipy\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension(\"bokeh\")\n",
    "\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "\n",
    "# Deze libraries zijn voor het verkrijgen van YouTube video gegevens. Dit is relevant voor het gebruik van de externe dataset.\n",
    "import pafy\n",
    "from youtube_dl import YoutubeDL\n",
    "import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens lezen we de eerste (toegewezen) dataset in. Hiervoor gebruiken we pandas.read_csv en slaan we dit op in de dataframe \"films\". \n",
    "Aangezien de dataset erg groot is, laten we voor nu alleen de eerste 5 rijen zien. Dit doen we door een variabele films.head() aan te roepen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films = pd.read_csv(\"movie.csv\", sep=\",\")\n",
    "films.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hetzelfde doen we met de tweede (externe) dataset, deze noemen we \"films_extern\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films_extern = pd.read_csv(\"ml-youtube.csv\", sep=\",\")\n",
    "films_extern.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien dus dat de eerste dataset uit veel films bestaat. De tweede dataset heeft er nog veel meer, maar niet alle data in de sets is bruikbaar, dus dat gaan we nu schoonmaken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stap 3: Data cleaning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan nu de data schoon maken. Om te beginnen schonen we beide datasets op door alle data die niet relevant is te verwijderen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwijder irrelevante kolommen.\n",
    "to_drop = [\"color\", \"facenumber_in_poster\", \"country\", \"aspect_ratio\", \"content_rating\"]\n",
    "films.drop(to_drop, inplace=True, axis=1)\n",
    "\n",
    "films_extern.drop(\"movieId\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwijder de rijen met NaN gegevens in beide datasets, aangezien dit data is die niet gebruikt kan worden.\n",
    "films = films.dropna()\n",
    "films_extern = films_extern.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haal alle duplicates eruit.\n",
    "films = films.drop_duplicates(subset=\"movie_title\")\n",
    "films_extern = films_extern.drop_duplicates(subset=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haal een whitespace weg in de eerste dataset die er niet in hoort te zitten.\n",
    "# We slicen de laatste 7 characters van de title column (het jaar dat de film uitkwam) in de tweede dataset weg,\n",
    "# zodat de column overeen komt met de column in de eerste dataset.\n",
    "films.update(films[\"movie_title\"].str[:-1])\n",
    "films_extern.update(films_extern[\"title\"].str[:-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We setten de indexes van beide datasets naar de titel van de films.\n",
    "films.set_index(\"movie_title\", inplace=True)\n",
    "films_extern.set_index(\"title\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We sorteren beide datasets zodat de waardes gelijk zullen zijn.\n",
    "films = films.sort_index()\n",
    "films_extern = films_extern.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu ziet de eerste dataset er zo uit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ziet de tweede dataset er zo uit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films_extern.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zijn nu klaar met het opschonen van de datasets. We kunnen ze nu gaan analyseren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stap 4: Data exploration & analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de data te verkennen en er een betere grip op te krijgen zullen wij een paar commando's loslaten op de verwerkte data. Als eerste zullen wij een *.describe()* functie gebruiken om een overzicht te krijgen van alle info van de numerieke waardes. Op deze manier kunnen wij bijvoorbeeld de gemiddelde lengte van een film zien. Dit is bij deze dataset dus 105 minuten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "films.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de data verder te verkennen en een beter gevoel te krijgen kunnen wij gebruik maken van grafieken. Zo staat hieronder bijvoorbeeld een staafdiagram van het aantal films per jaartal. In de x-as staat het jaartal, deze zijn gesorteerd bij het aantal films (in de y-as) er in dat jaartal zijn uitgekomen die in deze dataset staan. De meeste films uit deze dataset komen dus uit 2002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Maak een bar-chart met behulp van Matplotlib\n",
    "films[\"title_year\"].value_counts().plot(kind=\"bar\", \n",
    "                                        figsize=(20,5),\n",
    "                                        width=0.5, \n",
    "                                        color=\"#444444\");\n",
    "\n",
    "plt.xlabel(\"Jaartal\", labelpad=14)\n",
    "plt.ylabel(\"Aantal films\", labelpad=14)\n",
    "plt.title(\"Aantal films per jaartal\", y=1.02)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onderzoeksvragen\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor deze pipeline moeten er verschillende onderzoeksvragen worden uitgewerkt, elk met hun eigen antwoord en andere manier van oplossen. Deze zullen nu één voor één worden behandeld."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vraag 1: Hoeveel effect heeft de lengte van een trailer op de omzet van de film?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trailers zijn een belangrijk onderdeel van films. Je wilt immers wel enigzins weten wat je kan verwachten van de film.<br>\n",
    "Dit kan ook een factor spelen in de omzet van de film, want als de trailer slecht is zal je waarschijnlijk ook niet snel naar de film gaan en dan zal de film dus ook minder omzet hebben.<br>\n",
    "We gebruiken hier alleen de lengte van de trailer om het simpel te houden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor deze vraag maken we gebruik van de externe dataset. Zoals je misschien al hebt kunnen raden bestaat de externe dataset uit ID's voor YouTube video's. Deze verwijzen naar de trailers van de films van de toegewezen dataset. We hebben bij stap 3 beide datasets geprocessed en gecleaned. Deze gaan we nu mergen tot 1 dataframe en noemen we *'films_extern_merge'*.<br>Het idee is om de youtubeId column van de tweede dataset te verwerken in de eerste dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omdat de youtubeId column het enige is wat relevant is, is dat ook het enige veld dat we toevoegen. \n",
    "# De indexes van de eerste en tweede dataset worden samengevoegd tot 1 index genaamd title.\n",
    "films_extern_merge = pd.merge(films, films_extern, left_index=True, right_index=True)\n",
    "films_extern_merge.index.name = \"title\"\n",
    "\n",
    "# Tot slot droppen we de niet-relevante kollomen. \n",
    "# Om code te besparen, overschrijven we alleen de dataframe met de relevante kollomen.\n",
    "films_extern_merge = films_extern_merge[[\"gross\", \"youtubeId\"]]\n",
    "films_extern_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kunt zien dat er nu ongeveer 3000 films zijn. Dit is bijna de helft minder dan er in de oorspronkelijke eerste dataset stond. Dit is omdat veel films geen trailer op YouTube hebben staan.<br>\n",
    "We zullen deze gemergede dataset alleen voor deze vraag gebruiken. Laten we beginnen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier komt de **pafy** library ter zake. Om een voorbeeld te geven over wat het kan doen maken we eerst een video variabele aan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Om het simpel te houden gebruiken we voor nu maar de youtubeId van de eerste film in de dataframe.\n",
    "url = films_extern_merge.iloc[0, -1]\n",
    "video = pafy.new(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Van deze video kunnen we nu verschillende data ophalen, hier een paar voorbeelden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De titel van de video\n",
    "print(\"De titel van de video is: \\n\" + str(video.title))\n",
    "print(\"\\n\")\n",
    "\n",
    "# De lengte van de video in secondes\n",
    "print(\"De lengte van de video in secondes is: \\n\" + str(video.length))\n",
    "print(\"\\n\")\n",
    "\n",
    "# De concrete duratie van de video\n",
    "print(\"De concrete duratie van de video is: \\n\" + str(video.duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er zijn nog veel andere gegevens die kunnen worden opgehaald met behulp van pafy, maar hiervoor is een YouTube API account nodig en is ook niet voor ons relevant. We focussen ons op de **concrete duratie** van de video.\n",
    "\n",
    "Nu komen we op onze vraag, want heeft de duratie van de trailer invloed op de omzet van de film? Om daar achter te komen maken we nieuwe dataframe aan, deze pakt 100 willekeurige films uit de dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# De dataframe heet \"random_films\".\n",
    "random_films = films_extern_merge.sample(n = 100)\n",
    "\n",
    "# In deze list slaan we zometeen de duraties op.\n",
    "duratie = []\n",
    "\n",
    "# We loopen door random_films heen en extracten van elke video de duratie in secondes.\n",
    "# LET OP! Dit duurt een tijdje, aangezien er elke keer opnieuw een HTTP request wordt gemaakt. \n",
    "# Je kunt ook de errors en warnings negeren.\n",
    "for x in random_films[\"youtubeId\"].values:\n",
    "    try:\n",
    "        # We appenden de lengte van de trailer toe aan de list.\n",
    "        duratie.append(pafy.new(x).length)\n",
    "    except Exception:\n",
    "        # Sommige video's zijn niet meer te zien op YouTube, hier kan de data dus ook niet van worden opgehaald.\n",
    "        # Maar aangezien de waardes niet door elkaar mogen lopen, appenden we een Null waarde.\n",
    "        duratie.append(None)\n",
    "        continue\n",
    "\n",
    "# We voegen een kolom toe met de waardes van duratie.\n",
    "random_films[\"trailer_length\"] = duratie\n",
    "\n",
    "# We halen alle trailers eruit met een duratie van meer dan 400 seconden, aangezien deze vaak niet kloppen.\n",
    "random_films = random_films[random_films.trailer_length < 400]\n",
    "random_films"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu maken we een mooie scatter-plot om te zien of er een verband is tussen de omzet en trailer duratie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak een (regressie) scatter-plot met behulp van Seaborn.\n",
    "reg_plot = sns.regplot(random_films[\"trailer_length\"], random_films[\"gross\"],\n",
    "                       scatter_kws={\"color\": \"black\"}, \n",
    "                       line_kws={\"color\": \"red\"})\n",
    "\n",
    "# Voeg kenmerken toe aan de plot.\n",
    "reg_plot.set_xlabel(\"Trailer lengte in seconden\")\n",
    "reg_plot.set_ylabel(\"Omzet\")\n",
    "reg_plot.set_title(\"Scatter-plot van trailer lengte en omzet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elke uitkomst die je krijgt zal een ander resultaat geven, maar wat wel duidelijk is in elke uitkomst is dat er geen specifiek partroon te zien is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen dus concluderen dat er **geen** duidelijk verband is tussen de lengte van de trailer en de omzet van de film."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stap 5. Model building\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bij deze stap worden de geleerde methoden en machine learning technieken toegepast om de onderzoeksvragen te beantwoorden. Hierbij worden de resultaten gevalideerd en gevisualiseerd en worden de uitkomsten verklaard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vraag 2: Is een film succesvoller op basis van het aantal likes die een acteur (of acteurs) heeft/hebben op Facebook?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social media speelt tot op de dag van vandaag een hele belangrijke rol in ons dagelijks leven. Overal zien we beroemdheden en sommige mensen willen heel graag op deze beroemdheden lijken. Hierdoor wordt het gedrag van een individu bepaald. \n",
    "\n",
    "Tegenwoordig draaien de meeste dingen om likes en dat geldt ook voor deze deelvraag. Is het echt waar dat een film succesvoller is op basis van het aantal likes die een acteur (of acteurs) heeft/hebben op Facebook?\n",
    "\n",
    "Om die vraag te kunnen beantwoorden, moeten we eerst een beoordelingscriterium langs. Dit criterium zal gaan over het correlatieonderzoek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlatieonderzoek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met behulp van correlatie wordt de samenhang gemeten tussen twee variabelen. \n",
    "\n",
    "Het is belangrijk dat je de waarde van een andere variabele goed kunt voorspellen o.b.v. waardes van een variabele die je al kent. Hoe groter de correlatie, des te hoger de voorspellingskracht is.<br>\n",
    "Om deze vraag te kunnen beantwoorden, worden de variabelen IMDB-score en het gemiddelde aantal likes van de acteurs genomen.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder maken we eerst een extra kolom aan die het gemiddelde neemt van het aantal likes van de acteurs. Deze kolom voegen we toe aan de dataset films:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Voeg een kolom van het gemiddeld aantal likes van de acteurs toe aan de dataset films.\n",
    "films[\"mean_likes_actors\"] = (films[\"actor_1_facebook_likes\"] + \n",
    "                              films[\"actor_2_facebook_likes\"] + \n",
    "                              films[\"actor_3_facebook_likes\"]) / 3\n",
    "films"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals gezegd hebbende worden de variabelen IMDB-score en mean_likes_actors gebruikt. Hieronder wordt een scatter-plot gemaakt van deze variabelen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak gebruik van de Seaborn style.\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# Maak een scatter-plot van de variabelen.\n",
    "plt.scatter(films.imdb_score, films.mean_likes_actors, \n",
    "            s=40, \n",
    "            c=\"red\", \n",
    "            edgecolor=\"black\", \n",
    "            linewidth=0.75, \n",
    "            alpha=0.75)\n",
    "\n",
    "# Voeg kenmerken toe aan de plot.\n",
    "plt.xlabel(\"IMDB-score\")\n",
    "plt.ylabel(\"Aantal likes\")\n",
    "plt.title(\"Correlatie tussen IMDB-score en aantal likes\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals te zien is liggen de punten heel dicht op elkaar. Nu laten we nog even de r-waardes (richtingscoëfficient) zien van de correlatie tussen deze twee variabelen. Hiervoor maken we een aparte dataset aan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Voeg de kolommen imdb_score en mean_likes_actors toe aan een nieuwe dataset.\n",
    "films_correlation = films[[\"imdb_score\", \"mean_likes_actors\"]]\n",
    "films_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toon de correlatie tussen de twee variabelen.\n",
    "films_correlation.corr().style.background_gradient(cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We hebben een aparte dataset aangemaakt voor deze correlatie, omdat de andere gegevens niet relevant zijn voor het beantwoorden van de vraag. Mocht u geïntereseerd zijn in de correlatie met alle variabelen, kunt u het onderstaande statement runnen:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geef een overzicht van de correlatie met alle variabelen.\n",
    "# films.corr().style.background_gradient(cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor een goede correlatie is het belangrijk dat de richtingscoëfficient dicht bij de 1 zit ($ -1 ≤ r ≤ 1$). We zien uit de bovenstaande gegevens dat de richtingscoëfficient voor imdb_score en mean_likes_actors 0.187995 is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er is sprake van een positieve correlatie, maar er is **geen** sprake van een sterk verband tussen het succes van een film en het aantal likes van acteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vraag 3: In hoeverre is de omzet van een film te voorspellen op basis van de populariteit op Facebook en IMDB zelf?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Omzet is erg belangrijk voor een film. Het is immers waar een film voor wordt gemaakt: om omzet te draaien. Deze omzet komt natuurlijk van alle mensen die deze film hebben gezien in de bioscoop en uiteindelijk ook de DVD's. <br>\n",
    "Maar natuurlijk gaat de gemiddelde persoon niet naar elke film die ooit uitkomt. Als een film een lage score heeft op IMDB of weinig Facebook likes heeft, geeft dat al gauw een signaal dat de film niet zo goed is. Het is dus veilig om te zeggen dat zo'n score invloed heeft op de populariteit van een film.\n",
    "\n",
    "Maar heeft dit ook veel effect op de omzet van de film? En tot hoeverre kunnen we hiermee de omzet van toekomstige films voorspellen? Het criterium dat valt onder deze vraag is **supervised machine learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised machine learning is gebaseerd op een dataset waarvan de uitkomst al bekend is (*labeled*). Dit houdt in dat we de machine letterlijk \"begeleiden\" in zijn taak om iets uit te voeren. We geven de machine data om te onderzoeken en zorgen dat we deze een goed antwoord kan geven.<br>\n",
    "Onder supervised machine learning worden er binnen het vak Data Science twee technieken verstaan:\n",
    "    \n",
    "|Techniek                       |Omschrijving                          |                                \n",
    "|:------------------------------|:-------------------------------------|\n",
    "|Lineaire regressie             |Lineaire regressie probeert de relatie tussen twee variabelen te modelleren door een **lineaire vergelijking** aan te passen aan de waargenomen gegevens.   |\n",
    "|Classificatie                  |Classificatie is een geordende reeks gerelateerde categorieën die wordt gebruikt om gegevens te **groeperen op basis van overeenkomsten**. Binnen het vak Data Science bevat het 2 onderdelen: **Decision Trees** en **k-Nearest Neighbours**.                                                  |\n",
    "\n",
    "Om een betrouwbaar onderzoek uit te voeren kunnen we kiezen tussen lineaire regressie of classificatie. We beginnen met kijken of lineaire regressie geschikt is, dan classificatie. Maar voordat we beginnen moeten we de data **standaardiseren** aan de hand van een **z-score**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We defineren een nieuwe dataframe met alleen de relevante data.\n",
    "films_sml = films[[\"gross\", \"imdb_score\", \"movie_facebook_likes\"]].copy()\n",
    "cols = list(films_sml.columns)\n",
    "cols.remove('gross')\n",
    "\n",
    "# We genereren een z-score voor imdb_score en movie_facebook_likes.\n",
    "for col in cols:\n",
    "    col_zscore = col + '_zscore'\n",
    "    films_sml[col_zscore] = (films_sml[col] - films_sml[col].mean())/films_sml[col].std(ddof=0)\n",
    "    \n",
    "# We vervangen de dataframe met de z-score waardes en 500 willekeurige films.\n",
    "films_sml = films_sml[[\"gross\", \"imdb_score_zscore\", \"movie_facebook_likes_zscore\"]].sample(n=500, random_state=1)\n",
    "films_sml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben de data nu gestandaardiseerd. Dit betekent dat de data is veranderd om een gemiddelde van 0 en een standdaardeviatie van 1 te hebben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan nu kijken of we lineaire regressie kunnen gebruiken. Een eis daarvoor is dat de data een **correlatie** moet hebben van minimaal _0.7_ (positieve correlatie) of maximaal _-0.7_ (negatieve correlatie). We kunnen de correlatie op deze manier berekenen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toon de correlatie.\n",
    "films_sml.corr().style.background_gradient(cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien dat tussen de kolommen te weinig correlatie ligt. Alleen bij dezelfde kolom zien we een correlatie van 1, maar dat kunnen we niet gebruiken.<br>\n",
    "Kortom: we kunnen lineaire regressie **niet** gebruiken omdat er simpelweg te weinig correlatie is, ook al is de data genormaliseerd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maar hoe zit het met classificatie? Dat gaan we nu uitzoeken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals eerder vermeld vallen er binnen het vak Data Science 2 technieken onder classificatie: **Decision Trees** en **k-Nearest Neighbours**. Binnen deze context kunnen we alleen gebruik maken van Decision Trees. De techniek k-Nearest Neighbours is namelijk voor het indelen van een **nieuw object**, wat in principe niet kan bijdragen aan het beantwoorden van de vraag.\n",
    "\n",
    "Decision trees is een algoritme dat telkens een vraag bedenkt om de bestaande objecten in te delen in groepen, totdat deze uiteindelijk nauwkeurig zijn ingedeeld. Er wordt mee voorspeld wat het type is van verschillende cultivars, bijvoorbeeld een appel als je fruit gaat onderzoeken.<br>\n",
    "In dit geval zal het proberen om de types IMDB score of facebook likes te vinden.<br>\n",
    "Laten we beginnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We importeren de benodigde libraries van scikit learn.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from graphviz import Source\n",
    "from IPython.display import SVG\n",
    "\n",
    "# We stellen de variabele X op, deze vertegenwoordigd de feature matrix (X-as).\n",
    "# Het bevat de totale filmscore op IMDB en de het totale aantal facebook likes per film.\n",
    "feature_cols = [\"imdb_score_zscore\",\"movie_facebook_likes_zscore\"]\n",
    "\n",
    "X = films_sml[feature_cols]\n",
    "\n",
    "# We stellen we de variabele Y op, deze vertegenwoordigd de target vector(Y-as).\n",
    "# Het bevat de totale omzet per film.\n",
    "Y = films_sml.gross\n",
    "\n",
    "# We splitten de data op in test en training sets. 75% van de data gaat naar de training set, 25% gaat naar de test set.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)\n",
    "\n",
    "# We instantieeren de decision tree classifier.\n",
    "clf = DecisionTreeClassifier(max_depth=10, random_state=10) \n",
    "\n",
    "# We fitten de decision tree op de training sets.\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# We printen de nauwkeurigheidsscore van de voorspelling.\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er is een 0.0 in nauwkeurigheid. Dit is heel slecht, want het betekent dat er helemaal geen prediction gemaakt kan worden van deze gross. We kunnen dit checken met graphviz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We genereren een graph met de decision tree en visualiseren die.\n",
    "graph = Source(tree.export_graphviz(clf, out_file=None, feature_names=X.columns))\n",
    "SVG(graph.pipe(format=\"svg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze graphic is absoluut veel te groot en je wordt er niet wijzer uit. We kunnen dus concluderen dat ook met decision trees de omzet niet goed voorspeld kan worden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met lineaire regressie kan **geen** goede voorspelling worden gemaakt, aangezien de correlatie tussen de omzet en IMDB score/facebook likes te laag is en er dus geen regressie toegepast mag worden. Met decision trees kan er ook **geen** goede voorspelling worden gemaakt omdat de data niet goed te scheiden is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vraag 4: Wat voor voorspelling kan er worden gemaakt over de omzet gebaseerd op de combinatie van het budget en het aantal likes op Facebook e.d.?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het criterium dat valt onder deze vraag is **unsupervised machine learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised machine learning is gebaseerd op datasets zonder specifieke uitkomst (*unlabeled*). Hierbij probeer je groepen/indelingen te vinden die nuttig zijn (*pattern recognition*). Onder supervised machine learning worden er binnen het vak Data Science twee technieken verstaan:\n",
    "\n",
    "|Techniek                       |Omschrijving                          |                                \n",
    "|:------------------------------|:-------------------------------------|\n",
    "|Clustering                     |Het doel van clustering is om vanuit de kenmerken zelf groepen te laten vormen. Binnen het vak Data Science valt het onder twee onderdelen: **k-Means** en **Gaussian Mixture Model**|\n",
    "|Dimensionality Reduction       |Het doel van dimensionality reduction is eerst de dataset vereenvoudingen door het verminderen of samenvoegen van kenmerken; en dan groepen laten vormen. Deze valt buiten de scope van het vak.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor het gebruik van unsupervised machine learning moeten we dus clustering toepassen. De techniek die we gaan gebruiken is k-Means. Hiervoor is gekozen omdat k-Means een veelgebruikte en eenvoudig te begrijpen clustering techniek is. Je zoekt *k* verchillende clusters in een verzameling gegevens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor deze vraag gaan we een voorspelling van omzet maken gebaseerd op het budget, het aantal likes op facebook en de score op IMDB van de films. Om te beginnen maken we een paar nieuwe dataframes met de relevante data en normaliseren we deze 1 voor 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films_facebook = films[[\"gross\", \"movie_facebook_likes\"]].copy()\n",
    "films_facebook = (films_facebook - films_facebook.mean()) / (films_facebook.max() - films_facebook.min())\n",
    "\n",
    "films_imdb = films[[\"gross\", \"imdb_score\"]].copy()\n",
    "films_imdb = (films_imdb - films_imdb.mean()) / (films_imdb.max() - films_imdb.min())\n",
    "\n",
    "films_budget = films[[\"gross\", \"budget\"]].copy()\n",
    "films_budget = (films_budget - films_budget.mean()) / (films_budget.max() - films_budget.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan nu voor de 3 verschillende kolommen (budget, imdb_score en movie_facebook_likes) scatterplots en clusters maken met de gross kolom. We beginnen met gross en budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We maken een scatter-plot tussen gross en budget.\n",
    "plt.scatter(films_budget[\"budget\"], films_budget[\"gross\"],\n",
    "                          s=40, \n",
    "                          c=\"blue\", \n",
    "                          edgecolor=\"black\", \n",
    "                          linewidth=0.75, \n",
    "                          alpha=0.75)\n",
    "\n",
    "# Voeg kenmerken toe aan de plot.\n",
    "plt.xlabel(\"Budget\")\n",
    "plt.ylabel(\"Omzet\")\n",
    "plt.title(\"Scatter-plot van budget en omzet\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan nu kijken of we enige clusters kunnen vinden in dit scatter-plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We importeren de benodigde libraries.\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# We instantieeren een KMeans, stellen het aantal clusters in en fitten deze op de dataframe. Voor nu zoeken we er 2.\n",
    "kmeans = KMeans(n_clusters=2).fit(films_budget)\n",
    "\n",
    "# We printen de middelpunten.\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "# We voegen een nieuwe kolom \"group\" aan, dat weergeeft in welke cluster elke rij zich in bevindt.\n",
    "films_budget[\"group\"] = kmeans.labels_\n",
    "films_budget\n",
    "\n",
    "# We genereren een scatter-plot met k-mean opties.\n",
    "plt.scatter(films_budget[\"budget\"], films_budget[\"gross\"], \n",
    "            s=40,\n",
    "            c=films_budget[\"group\"], \n",
    "            cmap=\"plasma\",\n",
    "            edgecolor=\"black\", \n",
    "            linewidth=0.75, \n",
    "            alpha=0.75)\n",
    "\n",
    "# Voeg kenmerken toe aan de plot.\n",
    "plt.xlabel(\"Budget\")\n",
    "plt.ylabel(\"Omzet\")\n",
    "plt.title(\"Cluster tussen budget en omzet\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien hier 2 duidelijke clusters voor budget en gross. We zien dat de meeste films veel meer omzet draaien dan hun oorspronkelijk budget. Maar in de onderste cluster zien we ook een klein dozijn aan films die een heel hoog budget had, maar minder omzet maakte dan het budget. We kunnen hieruit concluderen dat een budget meestal lager is dan omzet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan nu hetzelfde doen, maar met movie_facebook_likes in plaats van budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We maken een scatter-plot tussen gross en movie_facebook_likes.\n",
    "plt.scatter(films_facebook[\"movie_facebook_likes\"], films_facebook[\"gross\"],\n",
    "                            s=40, \n",
    "                            c=\"blue\", \n",
    "                            edgecolor=\"black\", \n",
    "                            linewidth=0.75, \n",
    "                            alpha=0.75)\n",
    "\n",
    "# Voeg kenmerken toe aan de plot.\n",
    "plt.xlabel(\"Movie Facebook likes\")\n",
    "plt.ylabel(\"Omzet\")\n",
    "plt.title(\"Cluster tussen omzet en movie Facebook likes\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De data is hier meer verspreid, dus we zullen nu 3 clusters zoeken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We instantieeren een KMeans, stellen het aantal clusters in en fitten deze op de dataframe. Voor nu zoeken we er 3.\n",
    "kmeans = KMeans(n_clusters=3).fit(films_facebook)\n",
    "\n",
    "# We printen de middelpunten.\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "# We voegen een nieuwe kolom \"group\" aan, dat weergeeft in welke cluster elke rij zich in bevindt.\n",
    "films_facebook[\"group\"] = kmeans.labels_\n",
    "films_facebook\n",
    "\n",
    "# We genereren een scatter-plot met k-mean opties.\n",
    "plt.scatter(films_facebook[\"movie_facebook_likes\"], films_facebook[\"gross\"],\n",
    "            s=40,\n",
    "            c=films_facebook[\"group\"], \n",
    "            cmap=\"plasma\",\n",
    "            edgecolor=\"black\", \n",
    "            linewidth=0.75, \n",
    "            alpha=0.75)\n",
    "\n",
    "# Voeg kenmerken toe aan de plot.\n",
    "plt.xlabel(\"Movie Facebook likes\")\n",
    "plt.ylabel(\"Omzet\")\n",
    "plt.title(\"Cluster tussen omzet en movie Facebook likes\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien nu 3 clusters. Alle drie clusters zeggen 1 ding: omzet aan de hand van facebook likes kunnen erg verschillen. We zien bijvoorbeeld een film met een (genormaliseerde) omzet van 0.97, maar met een aantal (genormaliseerde) facebook likes van 0.09. En een film met een omzet van 0.19 maar met een aantal facebook likes van 0.98.<br>\n",
    "De bovenste cluster bevat de meest varierende data, de onderste cluster bevat de meeste standaard data en de middelste cluster bevat iets daar tussenin.<br>\n",
    "We kunnen concluderen dat facebook likes geen concreet effect hebben op de omzet van een film."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als laatste voeren we hetzelfde uit, maar met de score op IMDB. Hopelijk kunnen we hier een betere conclusie uit trekken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We maken een scatter-plot tussen gross en imdb_score.\n",
    "plt.scatter(films[\"imdb_score\"], films[\"gross\"],\n",
    "            s=40, \n",
    "            c=\"blue\", \n",
    "            edgecolor=\"black\", \n",
    "            linewidth=0.75, \n",
    "            alpha=0.75)\n",
    "\n",
    "# Voeg kenmerken toe aan de plot.\n",
    "plt.xlabel(\"IMDB-score\")\n",
    "plt.ylabel(\"Omzet\")\n",
    "plt.title(\"Scatter-plot van IMDB-score en omzet\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien hier een duidelijke **links-scheeve verdeling.** Dit kan betekenen dat de IMDB score de meeste betrouwbare bron is. Of dat zo is gaan we nu zien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We instantieeren een KMeans, stellen het aantal clusters in en fitten deze op de dataframe. Voor nu zoeken we er 2.\n",
    "kmeans = KMeans(n_clusters=2).fit(films_imdb)\n",
    "\n",
    "# We printen de middelpunten.\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "# We voegen een nieuwe kolom \"group\" aan, dat weergeeft in welke cluster elke rij zich in bevindt.\n",
    "films_imdb[\"group\"] = kmeans.labels_\n",
    "films_imdb\n",
    "\n",
    "# We genereren een scatter-plot met k-mean opties.\n",
    "plt.scatter(films_imdb[\"imdb_score\"], films_imdb[\"gross\"], \n",
    "            s=40,\n",
    "            c=films_imdb[\"group\"], \n",
    "            cmap=\"plasma\",\n",
    "            edgecolor=\"black\", \n",
    "            linewidth=0.75, \n",
    "            alpha=0.75)\n",
    "\n",
    "# Voeg kenmerken toe aan de plot.\n",
    "plt.xlabel(\"IMDB-score\")\n",
    "plt.ylabel(\"Omzet\")\n",
    "plt.title(\"Cluster tussen IMDB-score en omzet\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien hier 2 clusters. We zien en vrij duidelijk verschil tussen deze clusters. De linkse clusters weergeeft de data met de laagste (genormaliseerde) IMDB score. Als we kijken tussen de eerste en tweede cluster zien we dat de tweede cluster begint bij een steile verhoging van de (genormaliseerde) omzet, die ook bij de hoogste IMDB scores hoort.<br>\n",
    "We kunnen dus concluderen dat de omzet wel degelijk te voorspellen is via de score op IMDB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De omzet is wel goed te voorspellen met de score op IMDB, aangezien hier een duidelijke links-scheeve verdeling in te zien is.<br> \n",
    "De omzet kan minder goed worden voorspeld met het budget, aangezien de meeste films sowieso veel meer omzet draaien dan hun budget, en een laag budget ook niet altijd een lage omzet betekent.\n",
    "<br>\n",
    "De omzet kan bijna niet worden voorspeld met facebook likes, omdat deze data heel veel verschilt. Een film kan bijvoorbeeld 2 keer zoveel likes hebben als een andere film, maar alsnog minder omzet draaien dan de andere film."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothese-toets\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een filmcriticus heeft een hypothese: **de score van Engelstalige films is lager dan gemiddeld.**<br>\n",
    "Is deze hypothese correct? Dat gaan we uitzoeken aan de hand van een z-toets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De bekende gegevens zijn als volgt:\n",
    "- De steekproef (n) is 100 films.\n",
    "- De betrouwbaarheid van de steekproef is 90%.\n",
    "- De foutmarge (a) van de steekproef is 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we beginnen.<br>\n",
    "#### Stap 1: stel hypothesen op\n",
    "- **H0** = µ_engelstalige films >= gemiddelde score\n",
    "- **HA** = µ_engelstalige films < gemiddelde \n",
    "<br>\n",
    "\n",
    "Er is sprake van een **linkszijdige** toets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stap 2: neem een voldoende grote steekproef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We importeren de benodigde libraries.\n",
    "import scipy.stats as stats\n",
    "\n",
    "# We stellen het aantal van de steekproef in.\n",
    "n = 100\n",
    "\n",
    "# We nemen het gemiddelde van de populatie.\n",
    "mu = round(films[\"imdb_score\"].mean(), 1)\n",
    "print (\"Het gemiddelde van de populatie is {:.2f}.\".format(mu)) \n",
    "\n",
    "# We maken de steekproef van 100 willekeurige films. Van deze films is de IMDB score bekend en zijn ze engelstalig.\n",
    "sample = films[films[\"imdb_score\"] != None][films[\"language\"] == \"English\"].sample(n=n, random_state=1)\n",
    "\n",
    "# We berekenen het gemiddelde van de steekproef.\n",
    "x_ = round(sample[\"imdb_score\"].mean(), 1)\n",
    "print(\"Het gemiddelde van de steekproef is {:.2f}.\".format(x_))\n",
    "\n",
    "# We berekenen de standaarddeviatie van de steekproef.\n",
    "s = sample[\"imdb_score\"].std()\n",
    "print(\"De standaarddeviatie van de steekproef is {:.2f}.\".format(s))\n",
    "                     \n",
    "# We berekenen de standard error.\n",
    "se = s / np.sqrt(n)\n",
    "print(\"De standard error is {:.2f}.\".format(se)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stap 3: bepaal de foutmarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We stellen de foutmarge in.\n",
    "a = 0.1\n",
    "print(\"De foutmarge van de steekproef is {:.2f}.\".format(a))\n",
    "\n",
    "# We berekenen de grens van de Z-waarde\n",
    "z_grens = stats.norm.ppf((1-a))\n",
    "print(\"De grens z_waarde is {:.2f}\".format(z_grens))\n",
    "\n",
    "# We berekenen de concrete grenswaarde.\n",
    "grens = z_grens * se + mu\n",
    "print(\"De grenswaarde is {:.2f}\".format(grens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stap 4: bereken z-waarde en p-waarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We berekenen de Z-waarde.\n",
    "z = (x_ - mu) / se\n",
    "print(\"De Z-waarde is {:.2f}.\".format(z)) \n",
    "\n",
    "# We berekenen de P-waarde.\n",
    "p = stats.norm.sf(z)\n",
    "print(\"De P-waarde is {:.2f}.\".format(p) + \"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stap 5: conclusie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We kijken of de P-waarde meer of minder is dan de foutmarge.\n",
    "# Is het minder, dan wijzen we de nul hypothese af.\n",
    "# Is het meer of gelijk, dan accepteren we de nul hypothese.\n",
    "if p < a:\n",
    "    print(\"De P-waarde ({:.2f}) is kleiner dan de foutmarge ({:.2f}), dus we wijzen de nul hypothese af.\".format(p, a))\n",
    "elif p == a:\n",
    "    print(\"De P-waarde ({:.2f}) is gelijk aan de foutmarge ({:.2f}), dus we accepteren de nul hypothese.\".format(p, a))\n",
    "elif p > a:\n",
    "    print(\"De P-waarde ({:.2f}) is groter dan de foutmarge ({:.2f}), dus we accepteren de nul hypothese.\".format(p, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien dat de P-waarde hoger is dan de foutmarge en we de nul hypothese accepteren. We blijven dus nog sceptisch over de alternatieve hypothese.<br>\n",
    "Dit hoeft **niet** te betekenen dat de nul hypothese klopt, het betekent alleen dat we sceptisch blijven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stap 6. Visualization\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze stap is om niet alleen voor onszelf, maar ook voor u als lezer, inzicht te krijgen in de data van onze Data Science pipeline. \n",
    "\n",
    "Dankzij de interactieve visualisate met Holoviews kunt u invloed uitoefenen op wat u te zien krijgt qua analyses. Er wordt gebruik gemaakt van de Bokeh extensie en ipywidgets. De bijbehorende vraag bij deze stap is: *Wat is de netto omzet van de films in een specifiek jaar van uitkomst?* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vraag 5: Wat is de netto omzet van de films in een specifiek jaar van uitkomst?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het is voor een regisseur uiterst belangrijk om zoveel mogelijk geld te verdienen wanneer hij zijn film uitbrengt. Geld speelt immers een grote rol in ons leven. \n",
    "\n",
    "Daarom laten wij u nu zien wat de netto omzet is van alle films in het jaar van uitkomst. Dit doen wij eerst a.d.h.v. een bubble chart, omdat we hiervoor een vergelijking willen maken met drie categorieën (winst, jaar, film), over een tijd/periode. Daarna volgen enkele bar charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder maken we eerst een kopie van de films dataset. Daarna voegen we een extra kolom aan de nieuwe dataset die de omzet neemt van een film. Ook resetten we de index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Maak een kopie van de films dataset\n",
    "films_revenue = films[[\"title_year\"]].copy()\n",
    "\n",
    "# Voeg een extra kolom toe aan de dataset\n",
    "films_revenue[\"movie_net_revenue\"] = films[\"gross\"] - films[\"budget\"]\n",
    "\n",
    "# Reset de index zodat je makkelijker de gegevens van de filmtitel kan krijgen\n",
    "films_revenue.reset_index(inplace=True)\n",
    "films_revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *N.B.: om de omzet te kunnen berekenen zijn er slecht twee kolommen beschikbaar; vandaar dat we de omzet - het budget gebruiken.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu we de dataset hebben met de benodigde gegevens, kunnen we onze chart maken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak een bubble chart, waarbij je elke film indeeld in een subgroep als het ware.\n",
    "revenue_points = hv.Points(films_revenue, kdims=[\"title_year\", \"movie_net_revenue\"])\n",
    "\n",
    "# Style de plot.\n",
    "revenue_points.opts(xlabel=\"Jaar van de films\",\n",
    "                    ylabel=\"Netto omzet in $\",\n",
    "                    color=\"movie_title\",\n",
    "                    cmap=\"Category20\",\n",
    "                    line_color=\"black\",\n",
    "                    size=10,\n",
    "                    padding=0.1,\n",
    "                    width=1000,\n",
    "                    height=500,\n",
    "                    legend_position=\"right\",\n",
    "                    title=\"Netto omzet van films\")\n",
    "\n",
    "revenue_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals te zien is, is deze plot niet echt overzichtelijk en de datapunten staan te dicht op elkaar. Daarom gaan we laten zien hoe je wel voor elk jaar de omzet van alle films kunt zien. <br>\n",
    "Maar eerst, moet er een apart dataframe worden aangemaakt zodat de jaartallen netjes gesorteerd staan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak een kopie van de films_revenue dataset en sorteer op het jaar van nieuwste naar oudste film\n",
    "films_sort_year = films_revenue.copy().sort_values(by=\"title_year\", ascending=False)\n",
    "films_sort_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kunnen we de interactieve visualisatie voor de netto omzet van films in een specifiek jaar van uitkomst tonen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Gebruik van ipywidgets.\n",
    "import ipywidgets\n",
    "\n",
    "# Maak een dropdown voor jaartal.\n",
    "year_widget = ipywidgets.Dropdown(options=films_sort_year.title_year.unique().tolist(),\n",
    "                                  value=2016.0,\n",
    "                                  description=\"Kies een jaar:\")\n",
    "\n",
    "# Maak een select optie voor de omzet.\n",
    "measure_widget = ipywidgets.Select(options=[\"movie_net_revenue\"],\n",
    "                                     value=\"movie_net_revenue\",\n",
    "                                     description=\"Maatstaf:\")\n",
    "\n",
    "def create_bar_chart(year, measure):\n",
    "    \"\"\" Functie die ervoor zorgt dat er een bar chart wordt gemaakt per geselecteerd jaar \"\"\"\n",
    "    chart = hv.Bars(films_sort_year[films_sort_year.title_year == year], kdims=\"movie_title\", vdims=measure)\n",
    "    chart.opts(xlabel=\"Films\",\n",
    "               ylabel=\"Netto omzet in $\",\n",
    "               color=\"#444444\",\n",
    "               width=1200, \n",
    "               height=700, \n",
    "               xrotation=90,  \n",
    "               line_width=0.75, \n",
    "               alpha=1.75,\n",
    "               tools=[\"hover\"])\n",
    "    display(chart.opts(title=\"Jaar: \" f\"{year}\"))\n",
    "    \n",
    "    \n",
    "ipywidgets.interact(create_bar_chart, year=year_widget, measure=measure_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als extraatje kunt u hieronder ook voor elke film specifiek de netto omzet bekijken. Hierbij is er ook een bar chart gemaakt. \n",
    "> *Let op: de negatieve en positieve waardes blijven op dezelfde positie. Het kan dus even wennen zijn om dit goed te interpreteren, maar gelukkig hebben we daarvoor de Hovertool.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gebruik van ipywidgets.\n",
    "import ipywidgets\n",
    "\n",
    "# Maak een dropdown voor films.\n",
    "films_widget = ipywidgets.Dropdown(options=films_revenue.movie_title.unique().tolist(),\n",
    "                                  value=\"10 Things I Hate About You\",\n",
    "                                  description=\"Kies een film:\")\n",
    "\n",
    "# Maak een select optie voor de omzet.\n",
    "measure_widget = ipywidgets.Select(options=[\"movie_net_revenue\"],\n",
    "                                     value=\"movie_net_revenue\",\n",
    "                                     description=\"Maatstaf:\")\n",
    "\n",
    "def create_bar_chart(film, measure):\n",
    "    \"\"\" Funcite die ervoor zorgt dat er een Bar chart wordt gemaakt per geselecteerde film\"\"\"\n",
    "    chart = hv.Bars(films_revenue[films_revenue.movie_title == film], kdims=\"title_year\", vdims=measure)\n",
    "    chart.opts(xlabel=\"Jaar van de film\",\n",
    "               ylabel=\"Netto omzet in $\",\n",
    "               color=\"#444444\",\n",
    "               width=600, \n",
    "               height=450,\n",
    "               line_width=0.75, \n",
    "               alpha=1.75,\n",
    "               tools=[\"hover\"])\n",
    "    display(chart.opts(title=f\"{film}\"))\n",
    "        \n",
    "          \n",
    "ipywidgets.interact(create_bar_chart, film=films_widget, measure=measure_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er is met behulp van Holoviews, Bokeh en ipywidgets een plot gemaakt waarin te zien is wat de netto omzet van een film in het jaar van uitkomst is. Ook is het mogelijk om per specifieke film te kijken wat de omzet is. Deze deelvraag heeft geen concrete conclusie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leuk weetje\n",
    "- De eerste film die in onze dataset is opgenomen kwam uit in 1927. De film genaamd Metropolis had een verlies van 5.000.000 dollar. \n",
    "- De laatste film die in onze dataset is opgenomen kwam uit in 2016. De film genaamd Deadpool was het meest succesvol in dit jaar met een omzet van 305.024.263 dollar.\n",
    "- De totale omzet van de films in de periode van 1927 tot en met 2016 bedraagt maar liefst 33.980.758.451 dollar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stap 7. Communication\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als laatste stap volgt hier een beschrijving van enkele punten. \n",
    "\n",
    "Allereerst wordt er een beschrijving gegeven van hoe het bouwen van de Data Science-pipline is aangepakt. Daarna wordt er een beschrijving van de methode van dataverzamelingen en -bewerkingen gegeven. <br>Vervolgens wordt de dataopbouw, de analyses en de betekenis van de resultaten besproken. Er wordt concreet antwoord gegeven op de onderzoeksvragen en er volgt een beargumenteerde conclusie. Als laatst zijn er gebruikte bronnen te vinden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aanpak Data Science-pipeline\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor de aanpak van de Data Science-pipele hebben we eerst enkele onderzoeksvragen moeten bedenken en deze moeten inleveren bij de docent. Er was slechts één vraag waar er twijfel over was. Deze is later aangepast. In de eerste week zijn de stappen 1 t/m 3 van de pipeline uitgewerkt. Ook hebben we in de eerste week een externe dataset gevonden die aansloot op de deelvraag waarvoor deze nodig was. Nadat deze stappen waren afgerond, was het tijd voor het uitwerken van de deelvragen.\n",
    "\n",
    "Voor het uitwerken van deze deelvragen werd er in het begin gecommuniceerd via WhatsApp, maar later grotendeels via Discord.\n",
    "Voor de samenwerking werd er gebruik gemaakt van GitHub. Hierdoor konden we onderling mekaars werk lokaal overnemen en pushen naar de remote repository. Er werd eerst geprobeerd om samen te werken met Google Colaboratory, maar dit zorgde voor enkele performance problemen.\n",
    "\n",
    "In de laatste weken hebben we dit notebook gezamelijk in elkaar gezet en zijn we alle punten langsgelopen. Hierbij is er ook gecontroleerd op spelling, zinsopbouw, typo's en dergelijke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methode dataverzameling en -bewerking\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor de dataverzameling is er gebruik gemaakt van de dataset die we van de Hogeschool Utrecht hebben gekregen. Overigens hebben wij zelf via het internet een externe dataset gevonden. De link van deze datasets zijn te vinden in de bronnenlijst. Dit was stap 1 Data Collection van de pipeline.\n",
    "\n",
    "Voor de databewerking zijn de stappen 2 Data Processing en 3 Data Cleaning gedaan a.d.h.v. de college slides van de cursus Data Science. Ook is er gekeken naar een voorbeeld van een Jupyter Notebook over het onderzoek naar de Titanic. De link naar deze Kaggle is te vinden in de bronnenlijst.\n",
    "\n",
    "Voor stap 2 - Data Processing - hebben we de rauwe data ingeladen in Jupyter Notebook als dataframe. We hadden toen 2 datasets ingeladen: de toegewezen dataset en de externe dataset.\n",
    "\n",
    "Voor stap 3 - Data Cleaning - hebben we een aantal dingen gedaan:\n",
    "- Alle niet-relevante data gedropt.\n",
    "- Alle NaN gegevens gedropt.\n",
    "- Alle duplicates gedropt.\n",
    "- De movie titel kolommen in beide datasets overeen laten komen.\n",
    "- Nieuwe indexes ingesteld voor de dataframe. \n",
    "- De dataframes gesorteerd op de index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataopbouw, analyses en resultaten\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor de dataopbouw hebben we eerst de data verzameld. Vervolgens hebben de data opgeschoond en geprocessed (verwerkt). Daarna hebben we de data opgeschoond en zijn we begonnen met het verkennen en analyseren hiervan. Voor uitgebreider uitleg kunt u helemaal aan het begin kijken naar stap 1 t/m 4.\n",
    "\n",
    "Voor de analyses zijn er eerst een paar onderzoeksvragen bedacht. Vervolgens zijn deze onderzoeksvragen uitgewerkt in stap 4 t/m 6. De resultaten worden in het volgend hoofdstuk nader toegelicht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusies onderzoeksvragen\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier volgt een overzicht van de antwoorden op alle onderzoeksvragen die in deze Data Science-pipeline zijn behandeld.\n",
    "\n",
    "|Beoordeling                    |Onderzoeksvraag     |Conclusie                                                                  |\n",
    "|:------------------------------|:-------------------|:------------------------                                                                  |\n",
    "|Externe dataset                |Hoeveel effect heeft de lengte van een trailer op de omzet van de film?               |We kunnen concluderen dat er **geen** duidelijk verband is tussen de lengte van de trailer en de omzet van de film.\n",
    "|Correlatieonderzoek            |Is een film succesvoller op basis van het aantal likes die een acteur (of acteurs) heeft/hebben op Facebook?|Er is sprake van een positieve correlatie, maar er is **geen** sprake van een sterk verband tussen het succes van een film en het aantal likes van acteurs.                                                                                              | \n",
    "|Supervised machine learning    |In hoeverre is de omzet van een film te voorspellen op basis van de populariteit op Facebook en IMDB zelf?|Met lineaire regressie kan **geen** goede voorspelling worden gemaakt, aangezien de correlatie tussen de omzet en IMDB score/facebook likes te laag is en er dus geen regressie toegepast mag worden. Met decision trees kan er ook **geen** goede voorspelling worden gemaakt omdat de data niet goed te scheiden is.                                                                                                          |\n",
    "|Unsupervised machine learning  |Wat voor voorspelling kan er worden gemaakt over de omzet gebaseerd op de combinatie van het budget en het aantal likes op Facebook e.d.?|De omzet is wel goed te voorspellen met de score op IMDB, aangezien hier een duidelijke links-scheeve verdeling in te zien is.<br>De omzet kan minder goed worden voorspeld met het budget, aangezien de meeste films sowieso veel meer omzet draaien dan hun budget, en een laag budget ook niet altijd een lage omzet betekent.<br>De omzet kan bijna niet worden voorspeld met facebook likes, omdat deze data heel veel verschilt. Een film kan bijvoorbeeld 2 keer zoveel likes hebben als een andere film, maar alsnog minder omzet draaien dan de andere film.                                                                                              |\n",
    "|Z-toets|Een filmcriticus heeft een hypothese: **de score van Engelstalige films is lager dan gemiddeld.**<br>Is deze hypothese correct?|De P-waarde is hoger dan de foutmarge en we accepteren dus de nul hypothese. We blijven dus nog sceptisch over de alternatieve hypothese.<br>Dit hoeft **niet** te betekenen dat de nul hypothese klopt, het betekent alleen dat we sceptisch blijven.\n",
    "|Interactieve visualisatie      |Wat is de netto omzet van de films in een specifiek jaar van uitkomst?                      |Er is met behulp van Holoviews, Bokeh en ipywidgets een plot gemaakt waarin te zien is wat de netto omzet van een film in het jaar van uitkomst is. Ook is het mogelijk om per specifieke film te kijken wat de omzet is. Deze deelvraag heeft geen concrete conclusie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronnen\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De dataset van de Hogeschool Utrecht: <br>\n",
    "https://github.com/tijmenjoppe/ComputationalModelling-student/blob/master/casus/movie/movie.csv <br>\n",
    "\n",
    "De externe dataset: <br>\n",
    "https://grouplens.org/datasets/movielens/20m-youtube/ <br>\n",
    "\n",
    "Het voorbeeld Jupyter Notebook: <br>\n",
    "https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner <br>\n",
    "\n",
    "Voor het samenvoegen van het gemiddelde van meerdere kolommen: <br> \n",
    "https://stackoverflow.com/questions/34734940/row-wise-average-for-a-subset-of-columns-with-missing-values <br>\n",
    "\n",
    "Voor het correlatieonderzoek: <br>\n",
    "https://canvas.hu.nl/courses/7546/files/folder/slides?preview=765874 & https://canvas.hu.nl/courses/7546/pages/lineaire-regressie?module_item_id=248049 <br>\n",
    "\n",
    "Voor de uitleg van supervised machine learning: <br>\n",
    "https://canvas.hu.nl/courses/7546/files/folder/slides?preview=661608 <br>\n",
    "\n",
    "Voor de uitleg van lineaire regressie: <br> http://www.stat.yale.edu/Courses/1997-98/101/linreg.htm <br>\n",
    "\n",
    "Voor de uitleg van classificatie: <br>\n",
    "https://www.cso.ie/en/methods/classifications/classificationsexplained/ <br>\n",
    "\n",
    "Voor de uitleg van unsupervised machine learning en bijbehorende categorieën: <br>\n",
    "https://canvas.hu.nl/courses/7546/files/folder/slides?preview=661608 <br>\n",
    "\n",
    "Voor het tonen van de film met de meeste omzet: <br>\n",
    "https://stackoverflow.com/questions/15741759/find-maximum-value-of-a-column-and-return-the-corresponding-row-values-using-pan <br>\n",
    "\n",
    "Voor het resetten van de index: <br> \n",
    "https://www.youtube.com/watch?v=OYZNk7Z9s6I <br>\n",
    "\n",
    "Voor het sorteren van de kolommen op jaar: <br>\n",
    "https://www.youtube.com/watch?v=eu_pS_NWGD0 <br>\n",
    "\n",
    "Voor het maken van een scatter(point)-plot/bubble-chart: <br>\n",
    "https://www.youtube.com/watch?v=TRS8kyOimZI <br>\n",
    "\n",
    "Voor het stylen van de scatter-plot: <br> \n",
    "https://www.youtube.com/watch?v=zZZ_RCwp49g <br> \n",
    "\n",
    "Voor het sylen van Matplotlib plots: <br>\n",
    "https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.scatter.html<br>\n",
    "\n",
    "Voor het stylen van Seaborn plots: <br>\n",
    "https://seaborn.pydata.org/generated/seaborn.regplot.html & https://stackoverflow.com/questions/48145924/different-colors-for-points-and-line-in-seaborn-regplot <br>\n",
    "\n",
    "Voor het gebruik van ipywidgets: <br>\n",
    "https://ipywidgets.readthedocs.io/en/latest/user_install.html <br>\n",
    "\n",
    "Voor het werken met Holoviews: <br>\n",
    "https://www.youtube.com/watch?v=TRS8kyOimZI <br>\n",
    "\n",
    "Voor het customizen van de Holoviews plot: <br>\n",
    "http://holoviews.org/user_guide/Customizing_Plots.html <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Dat is voor mij om te weten, voor jullie om uit te zoeken*\n",
    "> *- Martijn J.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
